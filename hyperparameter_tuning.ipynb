{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840d6b81",
   "metadata": {},
   "source": [
    "# [DM 2025/26] Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1f85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8cf1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "N_SEARCH_ITERATIONS = 10\n",
    "N_CROSS_VALIDATION_FOLDS = 5\n",
    "SCORING = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40864616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_search = {\n",
    "    \"DecisionTree\": {\n",
    "        \"instance\": DecisionTreeClassifier(random_state=RANDOM_SEED),\n",
    "        \"hyperparameters\": {\n",
    "            \"max_depth\": list(range(1, 50)) + [None],\n",
    "            \"criterion\": [\"gini\", \"entropy\", \"log_loss\"]\n",
    "\t\t}\n",
    "\t},\n",
    "    \"NaiveBayes\": {\n",
    "        \"instance\": GaussianNB(),\n",
    "        \"hyperparameters\": {}\n",
    "\t},\n",
    "    \"MultinomialNB\": {\n",
    "        \"instance\": MultinomialNB(),\n",
    "        \"hyperparameters\": {}\n",
    "\t},\n",
    "    \"BernoulliNB\": {\n",
    "        \"instance\": BernoulliNB(),\n",
    "        \"hyperparameters\": {}\n",
    "\t},\n",
    "    \"KNN\": {\n",
    "        \"instance\": KNeighborsClassifier(),\n",
    "        \"hyperparameters\": {\n",
    "            \"n_neighbors\": range(1, 15),\n",
    "            \"metric\": [\"euclidean\", \"cosine\", \"minkowski\"]\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"SVC\": {\n",
    "\t\t\"instance\": SVC(random_state=RANDOM_SEED),\n",
    "\t\t\"hyperparameters\": {\n",
    "\t\t\t\"kernel\": [\"linear\", \"rbf\"],\n",
    "\t\t\t\"C\": [0.1, 1, 10, 100],\n",
    "\t\t\t\"gamma\": [\"scale\", 0.01, 0.1, 1]\n",
    "\t\t}\n",
    "\t},\n",
    "    \"MLP\": {\n",
    "        \"instance\": MLPClassifier(random_state=RANDOM_SEED),\n",
    "        \"hyperparameters\": {\n",
    "            \"hidden_layer_sizes\": range(1, 50),\n",
    "            \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\t\t}\n",
    "\t},\n",
    "    \"RandomForest\": {\n",
    "        \"instance\": RandomForestClassifier(random_state=RANDOM_SEED),\n",
    "        \"hyperparameters\": {\n",
    "            \"n_estimators\": range(100, 200),\n",
    "            \"max_depth\": list(range(1, 50)) + [None],\n",
    "            \"criterion\": [\"gini\", \"entropy\", \"log_loss\"]\n",
    "\t\t}\n",
    "\t},\n",
    "    \"AdaBoost\": {\n",
    "        \"instance\": AdaBoostClassifier(random_state=RANDOM_SEED),\n",
    "        \"hyperparameters\": {\n",
    "            \"n_estimators\": range(100, 200)\n",
    "\t\t}\n",
    "\t},\n",
    "    \"XGBoost\": {\n",
    "        \"instance\": XGBClassifier(),\n",
    "        \"hyperparameters\": {\n",
    "            \"n_estimators\": range(50, 200),\n",
    "            \"max_depth\": list(range(1, 50)) + [None],\n",
    "\t\t}\n",
    "\t}\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ac77d",
   "metadata": {},
   "source": [
    "Import dei dataset estratti dal Notebook Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb1cd368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueCountsResult(values=array([0, 1]), counts=array([2857, 1196]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dei dataset originali\n",
    "\n",
    "X_train = pd.read_csv(\"data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"data/y_train.csv\")\n",
    "y_test = pd.read_csv(\"data/y_test.csv\")\n",
    "\n",
    "np.unique_counts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8a0bed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueCountsResult(values=array([0, 1]), counts=array([1196, 1196]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dei dataset dopo undersampling\n",
    "\n",
    "X_train_under = pd.read_csv(\"data/X_train_under.csv\", sep=\",\")\n",
    "y_train_under = pd.read_csv(\"data/y_train_under.csv\", sep=\",\")#.squeeze().map(str)\n",
    "\n",
    "np.unique_counts(y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bde1497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniqueCountsResult(values=array([0, 1]), counts=array([2857, 2960]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dei dataset dopo oversampling\n",
    "\n",
    "X_train_over = pd.read_csv(\"data/X_train_over.csv\")\n",
    "y_train_over = pd.read_csv(\"data/y_train_over.csv\")#.squeeze().map(str)\n",
    "\n",
    "np.unique_counts(y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfee860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters for DecisionTree selected!\n",
      "Hyperparameters for NaiveBayes selected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:324: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:324: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py:1352: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 794, in fit\n    self._count(X, Y)\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 921, in _count\n    check_non_negative(X, \"MultinomialNB (input X)\")\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1775, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to MultinomialNB (input X).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m model_search:\n\u001b[32m     16\u001b[39m \trandom_search = RandomizedSearchCV(\n\u001b[32m     17\u001b[39m \t\testimator=model_search[model].get(\u001b[33m\"\u001b[39m\u001b[33minstance\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     18\u001b[39m \t\tparam_distributions=model_search[model].get(\u001b[33m\"\u001b[39m\u001b[33mhyperparameters\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \t\trandom_state=RANDOM_SEED\n\u001b[32m     23\u001b[39m \t)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \tres = \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \tres.best_params_, res.best_score_\n\u001b[32m     27\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHyperparameters for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m selected!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:2002\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   2000\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   2001\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2002\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2004\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   2005\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2006\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1030\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1026\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1027\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m   1028\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:479\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    473\u001b[39m     all_fits_failed_message = (\n\u001b[32m    474\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    478\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    482\u001b[39m     some_fits_failed_message = (\n\u001b[32m    483\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    484\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    489\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 833, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\base.py\", line 1336, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 794, in fit\n    self._count(X, Y)\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 921, in _count\n    check_non_negative(X, \"MultinomialNB (input X)\")\n  File \"c:\\Users\\fraca\\Desktop\\Universita\\Applied AI\\DM\\phoneme_classification\\DM\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1775, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to MultinomialNB (input X).\n"
     ]
    }
   ],
   "source": [
    "tuned_models = {}\n",
    "\n",
    "for sampling in (\"over\", \"under\", \"none\"):\n",
    "\tdata = X_train\n",
    "\tlabels = y_train\n",
    "\tif sampling == \"under\":\n",
    "\t\tdata = X_train_under\n",
    "\t\tlabels = y_train_under\n",
    "\telif sampling == \"over\":\n",
    "\t\tdata = X_train_over\n",
    "\t\tlabels = y_train_over\n",
    "\n",
    "\ttuned_models[sampling] = {}\n",
    "\n",
    "\tfor model in model_search:\n",
    "\t\trandom_search = RandomizedSearchCV(\n",
    "\t\t\testimator=model_search[model].get(\"instance\"),\n",
    "\t\t\tparam_distributions=model_search[model].get(\"hyperparameters\"),\n",
    "\t\t\tn_iter=N_SEARCH_ITERATIONS,\n",
    "\t\t\tscoring=SCORING,\n",
    "\t\t\tcv=N_CROSS_VALIDATION_FOLDS,\n",
    "\t\t\trandom_state=RANDOM_SEED\n",
    "\t\t)\n",
    "\n",
    "\t\tres = random_search.fit(data, labels)\n",
    "\t\tres.best_params_, res.best_score_\n",
    "\t\tprint(f\"Hyperparameters for {model} selected!\")\n",
    "\n",
    "\t\ttuned_models[sampling][model] = {\"params\": res.best_params_, \"accuracy\": res.best_score_}\n",
    "\n",
    "\t\twith open(\"tuned_hyperparameters.json\", mode=\"w\") as file:\n",
    "\t\t\tjson.dump(tuned_models, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062fc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a00de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
